---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# heartbeatr

<!-- badges: start -->
<!-- badges: end -->

An R package for processing data and automatically assessing cardiac frequency, specifically designed for use with PULSE systems (www.electricblue.eu/pulse).

## Installation

You can install the development version of **heartbeatr** from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("coastalwarming/heartbeatr")
```

## Examples

List PULSE files to be read:

```{r paths}
library(heartbeatr)
# but make sure they correspond to a single experiment/device
# ...here we use the package's example data
paths <- pulse_example("RAW_original_")
paths
```

There are two ways to read and process those data:

```{r process}
# step by step
pulse_data_sub   <- pulse_read(paths, msg = FALSE)
pulse_data_split <- pulse_split(
   pulse_data_sub,
   window_width_secs = 30,
   window_shift_secs = 60,
   min_data_points = 0.8, 
   msg = FALSE
   )
pulse_data_split <- pulse_optimize(pulse_data_split,
                                   target_freq = 40,
                                   bandwidth = 0.2)
heart_rates <- pulse_heart(pulse_data_split, msg = FALSE)

# or calling a single wrapper function
heart_rates <- PULSE(
  paths,
  # channels s5 to s10 are empty in the example data
  discard_channels  = paste0("s", 5:10), 
  window_width_secs = 30,
  window_shift_secs = 60,
  min_data_points   = 0.8,
  target_freq = 40,
  bandwidth   = 0.2,
  msg = FALSE
  )
```

Once processed, PULSE data is stored as a tibble with an average heart rate frequency for each channel/split window. The time is relative to the mid-point of the window. Frequencies are expressed in Hz and BPM. In addition, the following information is also provided, which can be used to classify or filter the data: **n**, the number of identified heart beats, **sd**, the standard deviation of the intervals between each pair of consecutive peaks, **ci**, the confidence interval of the Hz estimate (hz ± ci), and **bpm_ci**, the confidence interval of the BPM estimate (bpm ± bpm_ci).

```{r check}
heart_rates
```

You can easily use parallel computing with **heartbeatr** - just configure your R session properly **BEFORE** applying the PULSE workflow:

```{r parallel}
# this shows how your session is currently configured 
#   (typically defaults to "sequential", i.e., not parallelized)
future::plan()

# to make use of parallel computing (highly recommended)
future::plan("multisession")
future::plan()
```

The raw data underlying the heart rate frequency estimate (hz) can be inspected:

```{r plot1, fig.width = 10, fig.height = 5}
pulse_plot_raw(heart_rates, ID = "limpet_1", target_time = "2022-12-29 13:55", range = 2) 
# the split window for channel "limpet_1" closest to the target date 
#   provided with target_time is shown in the center:
#   - 2 more windows are shown before and after the target (because range had been set to 2)
#   - red dots show where the algorithm detected a peak
```

Beware of bad data - estimates of heart rate are always produced, regardless of the quality of the underlying data, but they may not be usable at all if the quality of that data is too poor.  

```{r plot_bad, fig.width = 10, fig.height = 5}
pulse_plot_raw(heart_rates, ID = "limpet_2", target_time = "2022-12-29 13:55", range = 2) 
# the channel "limpet_2" contains poor-quality data, where visual inspection clearly shows
# that the heart rate wasn't captured in the signal (lack of periodicity, inconsistent
# intervals between identified peaks)
```

A quick overview of the result of the analysis of the data from all channels:

```{r plot2, fig.width = 10, fig.height = 5}
pulse_plot(heart_rates)
# note that one could easily overlook the wider confidence intervals in all channels 
# other than "limpet_1" and erroneously continue analysing the output of the 
# pulse-processing algorithm - when in fact we have already determined that data 
# recorded in the channel "limpet_2" is too poor (the same is true for the other 
# channels as well).
```

The number of data points can be reduced:

```{r plot3, fig.width = 10, fig.height = 5}
heart_rates_binned <- pulse_summarise(heart_rates, 
                                      fun = mean, 
                                      span_mins = 3, 
                                      min_data_points = 0.8)
pulse_plot(heart_rates_binned)
```

A more detailed view of the channel "limpet_1", showing the Confidence Interval for each estimate of heart rate.
```{r one_channel, fig.width = 10, fig.height = 4}
pulse_plot(heart_rates, ID = "limpet_1", smooth = FALSE, bpm = TRUE)
```

Data points exceeding an arbitrary standard deviation can easily be removed. This is useful when dealing with long series of continuous data which were already collected with the intention to discard portions of data with higher variability which may be indicative of lower quality.

```{r thinning, fig.width = 10, fig.height = 4}
# arbritary threshold
max_sd <- 0.04

pulse_plot(dplyr::filter(heart_rates, sd <= max_sd), ID = "limpet_1", smooth = FALSE, bpm = TRUE)
```
